\chapter{Layout recognition for tabular data}

\todo{Nejdriv je potreba popsat co to vlastne dela a pak se teprv rejpat v tom proc to selhava.}
The extraction of table structures from a page poses various difficulties. Complications mostly arise when the input document does not correspond to the typical one-column, graphics-free layout. This may cause the spaces between individual page columns to be interpreted as table column spaces, which may lead to a complete rejection of any tables present in page columns. Additionally, complex layouts often cause difficulties when determining the reading order of the document. Therefore, in most cases, a \emph{layout analysis} first needs to performed.

\section{Layout analysis}

Layout analysis is the process of identifying and categorizing image document elements, such as figures, tables, forms, math symbols, headers, footers or simple paragraph text (\emph{geometric layout analysis}) and semantically labeling them according to their logical roles (\emph{logical layout analysis}).

In the previous chapter, we already covered the basics of geometric layout analysis, which is the same process as page segmentation~\cref{pageSegmentation}. The output of this process is a data structure containing information about the detected elements. A logical layout analysis is then applied on this output.

Logical layout analysis is used to determine the reading order of the image document. It adopts the idea of \emph{labels}, which provide an information about the semantic order and type of individual document elements. For example, a label might be just a number indicating the reading order (as presented in~\cref{fig:readingOrderExample}), or it could contain more complex information, such as ``table header'', ``page footer'', ``image caption'', etc.

The result of logical layout analysis is therefore often in a form of mapping of each element to its corresponding label. However, the determination of correct labels is sometimes hard even for human perception, as presented in~\cref{fig:readingOrderProblems}. With various differently aligned columns with different font sizes, or with image captions appearing on different sides of the image in every document, people often determine which elements belong together only according to their intuition (e.g. when reading about a recent earthquake, caption saying “Rescued puppy” probably belongs to the picture of a dog instead of a flooded beach, although in can be placed right in the middle of these two images).

Computers have no notion of such things. This is often a cause of many errors and a reason why a lot of OCR engines claim to work on only documents with specified layouts, e.g. single-column, non-graphical, etc.

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{img/tableDetection/readingOrderIssue.jpg}
\caption{Reading order problems. Determination of correct labels is sometimes hard even for human perception.} \label{fig:readingOrderProblems}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.5\linewidth]{img/tableDetection/readingOrder.jpg}
\caption{An example of layout analysis~\citep{hadjar2004xed}.}
\label{fig:readingOrderExample}
\end{figure}

Various heuristics are being used for determining labels~\cite{logicalLayoutTemplate}. In the following list, we will be concerned with the few of the most widely used:

\begin{itemize}
\item[\emph{Templates}]

The most simple and basic approach is the technique of the already mentioned templates. It is based on a limited number of predefined document layouts (\emph{templates}), which already contain the information about the structure of individual elements. An input document is then matched to these layouts. In the OCR engines that focus solely on processing a single type of documents (such as ticket validation, recipe or passport recognition, recognition of forms filled out by patients in hospitals), this process yields almost perfect results, even though it is a naive approach.

\item[\emph{Rule-based approaches}]

A human reader often determines the logical succession of document elements by font settings and locations of the elements. Rule-based approaches take advantage of this fact and create heuristic ``rules'' that determine the type of the element. For example, a rule for a page header could be ``has the smallest y-axis value, has font size above 22pt, is bold, and is the only element on its line''.

\item[\emph{Syntactic methods}]

These methods present the structure used for element labeling in a form of a set of formal (usually context free) grammars. These grammars contain rules for aggregating pixels into more structured entities until they form logical objects. Parsers for a syntactic analysis are automatically obtained from these grammars. They are then used to perform the actual labeling of the detected elements.

\item[\emph{Machine learning}]

Already mentioned in this thesis, a non-heuristic approach to logical layout analysis is the use of neural networks. Given enough information and time for training, the networks are able to determine the labeling on their own.

There exist various techniques of machine learning, distinguished by the way the neural networks are trained. For example, a neural network can be given a set of rules and input images, which leads the learning process to produce results similar to human observation. Also, it can be solely reliant on raw physical data and itself.

\end{itemize}

Worth mentioning are also techniques like \emph{Blackboard system} or \emph{Description language} or methods based on \emph{Hidden Markov Models}~\cite{logicalLayoutOther}.

Layout analysis is a crucial part of almost every OCR engine. If either geometric or logical layout analysis fails, the input of the recognition engine might contain corrupted data. This might lead to a significantly lower accuracy of the recognition process. 

Table recognition utilizes the output of layout analysis, and extracts table related information, such as table cells, headers and footers, from it. Other elements are discarded (e.g. floating text, graphics), as they are considered worthless.

\section{Table recognition}

The goal of table recognition is to determine if a table even is present on a page, and if yes, where and what its contents are\todo{content je jeden nepocitatelnej}. It\todo{what it? the table?} is often divided into two parts --- \emph{table detection} and \emph{table decomposition}, with table detection determining the presence and placement of a table, and table decomposition analyzing its contents and producing a meaningful structure of its representation.

\xxx{However, table detection often greatly depends on the decomposed structure of the table.}\todo{tohle nejde pochopit} For example, a table can be detected in the following way:

\begin{enumerate}
    \item find the individual lines (\emph{table decomposition})
    \item check which lines are aligned in a similar way (\emph{table detection})
    \item declare these lines to be in the same table (\emph{table decomposition})
    \item find different columns from the lines (\emph{table decomposition})
\end{enumerate}

If we were to first perform table detection and only then proceed to table decomposition, we would lose the important information about lines that we already obtained in step one. Therefore, many algorithms perform the table recognition process as a whole. \todo{tady je problem ze ctenar celej priklad pochopi tepre az docte sem, a nejspis to bude muset precist znova. Neslo by to napsat primejc?}

\xxx{Extraction of table elements poses various difficulties. These are usually linked to the structure of a table.}\todo{obvious} Although obtaining the elements of a simple $m{\times}n$ grid is an easy task achieved by a simple line detection algorithm (for example Hough transform~\cite{houghTransform}), the \xxx{missing presence}\todo{missing presence jsou 2 totalni protiklady, co takhle absence?} of cell borders requires more complicated heuristics. Moreover, tables contain\xxx{ing} cells of different sizes, various numbers of cells in different rows, complicated headers or footers, multi-line cells and many more also require more complex solutions. We present a few of the possible obstacles in~\cref{fig:tableRecognitionObstacles}.\todo{tady bysem ocekaval ze uz budes prezentovat spis ty reseni... tyhle priklady je potreba vysypat driv.}

\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{img/tableDetection/recognitionProblematic.jpg}
\caption{A few of the basic problems during table recognition: missing horizontal and vertical lines; missing information in cells; multi-line cells in the first column and header row; different alignment of header and content cells.}
\label{fig:tableRecognitionObstacles}
\end{figure}

In this section, we overview some of the \xxx{already} existing table recognition algorithms. For the purposes of this thesis, we will specifically focus on the table recognition implementation of the Tesseract engine.

\subsection{Tesseract table recognition} \label{tableFind}

The Tesseract engine has been originally used \xxx{solely} for character detection. Over the years, \xxx{however,}\todo{however je negativni, tohle je ale ve skutecnosti docela fajn} many features have been added, including a table detection and recognition algorithm --- \textsc{TableFind}. \todo{jmenovaci dovetky jsou osklivy a nikdo je nema rad, chces `including the TableFind algorithm for ...'}

\xxx{Presented by~\citet{tableDetHeterogeneous},}\todo{X and Y based TableFind on ...?} the TableFind recognition algorithm is based on already existing Tesseract's features, including layout analysis (\xxx{already mentioned}\todo{described?} in~\cref{sectionTessPageSegm}) and character detection (\cref{tesseractCharacterRecognition}). \xxx{Following are the individual steps} of the algorithm, along with their visualization in~\cref{fig:tesseractTableRecognition}: 

\begin{enumerate}
\item \emph{Layout analysis}

\xxx{This step}\todo{reference na strukturu. Chces: First, layout analysis is performed ...} is performed by the \xxx{already mentioned}\todo{zbytecny, proste se odkaz, a ten odkaz dej idealne do zavorek} \emph{tab-stop detection}~\cref{sectionTessPageSegm} included in the Tesseract library. The results of this step include not only a list of segmented blocks, but also the column layout (~\cref{fig:tessTableDet1}) and column partitions (sequences of connected components of the same type --- like text, image --- that do not cross any tab-line, presented in~\cref{fig:tessTableDet2}).

\item \emph{Identification of table partitions}

\xxx{The next step is to identify}\todo{word order; navic proc nerict proste `With the page layout available, Tesseract tries to identify ...'} text column partitions that could possibly belong to a table --- \emph{table partitions}. This process is based on heuristics, by identifying column partitions that contain at least one large gap between their connected components, consist of only one word, or overlap with other partitions along the y-axis.

This stage of the algorithm is performed quite aggressively, so although this process returns the desired table partitions, it also produces a lot of false \xxx{alarms}\todo{alarm = budik nebo sirena. Chces `false positives'}, \xxx{like}\todo{including!} section headings, page headers, footers, equations \xxx{and so on}\todo{etc. mozna chces neco jako `such as considering section headings, ....., as tables'}. A smoothing filter is applied to remove most of these unwanted partitions\todo{how? smoothing is usually more similar to `blur', which doesn't easily apply to tables}. However, as presented in~\cref{fig:tessTableDet3}, the presence of minor mistakes is not completely eliminated.

\item \emph{Detection of table columns}

\xxx{Presented}\todo{as shown in?} in~\cref{fig:tessTableDet4}, vertically aligned partitions are \xxx{simply} grouped into a single column. Columns with only one partition are then removed. This step \xxx{pays a close attention}\todo{attention je vlastnost kterou algoritmy nemaj, mozna to chces obratit ze se snazi udelat X tim ze vysledky dava do kontextu s page layoutem} to the page layout \xxx{itself}\todo{`itself' je jako `The King Himself'} and tries to prevent merging two distinct columns, which is often an issue in full-page tables.

\item \emph{\xxx{Formation}\todo{formation je formace, jako ze letadla letej srovnany vedle sebe aby vypadaly nebezpecnejsi. Table construction/aggregation?} of tables}

The goal of \xxx{this step} is to group table columns into a table. Here, a simple assumption \xxx{is made}\todo{tesseract assumes?} --- that flowing text does not share space with a table along the y-axis. Therefore, boundaries of table columns are expanded along the y-axis to the borders of the page columns that contain them. This results in \xxx{the creation}\todo{creation=stvoreni sveta. Word order -- in result, a b.box is created} of a bounding box for whole tables. \xxx{When it comes to}\todo{So it has come to this!} tables that span across multiple page columns, \xxx{these are} detected only if a table column exists that belongs to all of these page columns.

\item \emph{Removal of false positives}

\xxx{As the algorithm works quite aggressively, it produces a lot of false positives.}\todo{obvious} \xxx{This step}\todo{reference to structure} \xxx{analyzes}\todo{the literal step does not analyze anything, at this step the algorithm does analyze. Better to start with the problem: `Because of relatively greedy heuristic used in the previous step, non-tabular content may be falsely identified in a table. Therefore, Tesseract finally removes ....} tables with only one column and removes those that \xxx{do not suffice}\todo{tohle neznamena ze nevyhovujou (to je satisfy) ale ze jich jek necemu malo} \xxx{certain}\todo{tohle je zasadni, jestli mas priklad} heuristic conditions. This produces the final result (\cref{fig:tessTableDet5}).

\end{enumerate}

The algorithm has been proved to have a 86\% precision. The biggest problems have shown to be full-page tables, often resulting in over or under-segmentation, partial detection or detection of false positives~\citep{tableDetHeterogeneous}.

Another problem with TableFind is that currently, there exists no simple command that a user could run to see the output of this algorithm. To actually detect a table, a user must first write its own program that uses the functions of the added Tesseract table recognition files. Then, he needs to process the data the library returns and output them in a meaningful format, which requires a non-trivial knowledge of the Tesseract implementation.

We will further present the results of this algorithm in~\cref{resultsTableFind}, where we compare them to our implementation.
   
\begin{figure}
\centering
\begin{subfigure}{0.30\textwidth}
\includegraphics[width=\linewidth]{img/tableDetection/tableDetectionColumns.pdf}
\caption{Column layout.}
\label{fig:tessTableDet1}
\end{subfigure}
\quad
\begin{subfigure}{0.30\textwidth}
\includegraphics[width=\linewidth]{img/tableDetection/tableDetectionPartitions.pdf}
\caption{Column partitions.}
\label{fig:tessTableDet2}
\end{subfigure}
\quad
\begin{subfigure}{0.30\textwidth}
\includegraphics[width=\linewidth]{img/tableDetection/tableDetectionCandidate.pdf}
\caption{Candidate table partitions.}
\label{fig:tessTableDet3}
\end{subfigure}
\\
\begin{subfigure}{0.30\textwidth}
\includegraphics[width=\linewidth]{img/tableDetection/tableDetectionTabCols.pdf}
\caption{Table columns.}
\label{fig:tessTableDet4}
\end{subfigure}
\quad
\begin{subfigure}{0.30\textwidth}
\includegraphics[width=\linewidth]{img/tableDetection/tableDetectionResult.pdf}
\caption{Detected table regions.}
\label{fig:tessTableDet5}
\end{subfigure}
\caption{The process of Tesseract table recognition~\cite{tableDetHeterogeneous}.}
\label{fig:tesseractTableRecognition}
\end{figure}

\subsection{Other existing approaches}

\xxx{Besides}\todo{to znamena zovialni mimochodem} Tesseract, there exist various heuristic approaches \xxx{presented} for table detection. In this section, we \xxx{present} an overview of \xxx{a few of} them and \xxx{determine} what they have in common, as well as point out their advantages and disadvantages. Specifically, we will focus on T-Recs table recognition system~\citep{TRecs}, Medium-independent table detection~\citep{MediumTable}, pdf2table project~\cite{pdf2table} and an approach based on a hierarchical MXY tree page representation~\citep{tableDetectCesarini}. However, multiple other approaches also exist. Worth mentioning is also, for example, \emph{sparse line detection}~\cite{sparseLineDetection}, which already uses principles of machine learning. Some of the other methods are briefly mentioned by~\citet{otherDetection1} or~\citet{otherDetection2}.

\xxx{Presented as one of the first table detection algorithms}\todo{subsentence order} by~\citet{TRecs}, the \emph{T-Recs} table recognition system is based on a bottom-up approach of clustering word bounding boxes and building a ``segmentation graph''. \xxx{This results in creating} different regions of page, which are then evaluated by certain heuristic criteria for tables. \xxx{Although widely used in the past}\todo{v jak vzdaleny minulosti?}, this technique\xxx{s} has \xxx{a few} setbacks. T-Recs is controlled by a set of numerical parameters, which need to be \xxx{set}\todo{adjusted?} manually according to the layout of the page\todo{je to problem?}. \xxx{Moreover, it yields}\todo{to muze bejt v jedny vete bez Moreover} unsatisfactory results on multi-column documents.

Another algorithm was described by~\citet{MediumTable}. In single-column documents, a page can be easily segmented into individual textlines. The table detection problem is then perceived as an optimization problem, where the start and end textlines that belong to a table are identified by optimizing some quality function. However, this approach fails on multi-column documents, and on documents that contain more than one table.

\citet{tableDetectCesarini} describe\xxx{s} \xxx{another}\todo{proste `an'} approach based on the document \xxx{being}\todo{based on hierarchical MXY-tree-like representation ...} hierarchically represented by a structure similar to a MXY tree. The presence of a table is determined by searching the tree for parallel lines that contain white spaces, and other perpendicular lines between them. Located tables \xxx{can be}\todo{are?} merged on the basis of proximity and similarity criteria. However, this approach fails if no lines\todo{az tady mi doslo ze `lines' jsou `cell borders'} in tables are present\xxx{ --- which is usually the case of many tables.}\todo{redundant}

\xxx{Another method was presented by the }\todo{redundant, muzes aktivne `pdf2table method is based...'}\emph{pdf2table} project~\cite{pdf2table}. This method is based on assigning each text object of the page its positional attributes. By the evaluation of these attributes, text objects are then merged into single-lines (lines with only one text object), multi-lines (lines with more than one text object) and multi-line blocks (multiple multi-lines merged together). The table detection algorithm \xxx{is based}\todo{uz tam je moc based} on merging \todo{the?} multi-line blocks that may belong to the same table, with the help of a heuristic threshold that determines the greatest number of single-line objects between two multi-line blocks possible. This method also assumes the input to be a single-column document. \xxx{However, a}\todo{Despite of that, the} user can manually provide \xxx{it with an}\todo{information je nepocitatelny, a `provide it with' znamena neco jako `vybavit to na dlouhou cestu'} information about the number of columns, which yields more accurate results.

Although most of these methods produce satisfactory results when focusing on table detection, their support for the recognition of the individual elements in extracted tables is, in most cases, insufficient\todo{unsatisfactory? btw proc?}. As character recognition is usually not a part of these softwares, providing a complete table recognition would require their extension with the use of a quality text recognition engine. \xxx{This is the focus of our thesis and the main goal of our implementation.}\todo{tenhle odstavec je mozny vklidu vynechat, nebo napsat nekam na zacatek dalsi kapitoly}
